From: Talat Batheesh <talatb@mellanox.com>
Subject: [PATCH] BACKPORT: drivers/net/ethernet/mellanox/mlx5/core/fs_core.c

Change-Id: Ie3c02fef31d86215ad6ebdf4bc6c3a9514d3368f
---
 drivers/net/ethernet/mellanox/mlx5/core/fs_core.c | 69 ++++++++++++++++++++++-
 1 file changed, 66 insertions(+), 3 deletions(-)

diff --git a/drivers/net/ethernet/mellanox/mlx5/core/fs_core.c b/drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
index xxxxxxx..xxxxxxx 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
@@ -220,7 +220,11 @@ static const struct rhashtable_params rhash_fte = {
 	.min_size = 1,
 };
 
+#if !defined(HAVE_RHLTABLE) && defined(HAVE_NETNS_FRAGS_RHASHTABLE)
+static const struct bp_rhashtable_params rhash_fg = {
+#else
 static const struct rhashtable_params rhash_fg = {
+#endif
 	.key_len = FIELD_SIZEOF(struct mlx5_flow_group, mask),
 	.key_offset = offsetof(struct mlx5_flow_group, mask),
 	.head_offset = offsetof(struct mlx5_flow_group, hash),
@@ -470,7 +474,9 @@ static void del_hw_flow_table(struct fs_node *node)
 	fs_get_obj(ft, node);
 	dev = get_dev(&ft->node);
 	root = find_root(&ft->node);
+#ifndef MLX_DISABLE_TRACEPOINTS
 	trace_mlx5_fs_del_ft(ft);
+#endif
 
 	if (node->active) {
 		err = root->cmds->destroy_flow_table(root, ft);
@@ -486,7 +492,11 @@ static void del_sw_flow_table(struct fs_node *node)
 
 	fs_get_obj(ft, node);
 
+#if !defined(HAVE_RHLTABLE) && defined(HAVE_NETNS_FRAGS_RHASHTABLE)
+	bp_rhltable_destroy(&ft->fgs_hash);
+#else
 	rhltable_destroy(&ft->fgs_hash);
+#endif
 	fs_get_obj(prio, ft->node.parent);
 	prio->num_ft--;
 	kfree(ft);
@@ -528,7 +538,9 @@ static void del_sw_hw_rule(struct fs_node *node)
 	}
 
 	fs_get_obj(fte, rule->node.parent);
-	trace_mlx5_fs_del_rule(rule);
+#ifndef MLX_DISABLE_TRACEPOINTS
+       trace_mlx5_fs_del_rule(rule);
+#endif
 	if (rule->sw_action == MLX5_FLOW_CONTEXT_ACTION_FWD_NEXT_PRIO) {
 		mutex_lock(&rule->dest_attr.ft->lock);
 		list_del(&rule->next_ft);
@@ -566,7 +578,9 @@ static void del_hw_fte(struct fs_node *node)
 	fs_get_obj(fg, fte->node.parent);
 	fs_get_obj(ft, fg->node.parent);
 
+#ifndef MLX_DISABLE_TRACEPOINTS
 	trace_mlx5_fs_del_fte(fte);
+#endif
 	dev = get_dev(&ft->node);
 	root = find_root(&ft->node);
 	if (node->active) {
@@ -607,7 +621,9 @@ static void del_hw_flow_group(struct fs_node *node)
 	fs_get_obj(fg, node);
 	fs_get_obj(ft, fg->node.parent);
 	dev = get_dev(&ft->node);
+#ifndef MLX_DISABLE_TRACEPOINTS
 	trace_mlx5_fs_del_fg(fg);
+#endif
 
 	root = find_root(&ft->node);
 	if (fg->node.active && root->cmds->destroy_flow_group(root, ft, fg))
@@ -629,7 +645,11 @@ static void del_sw_flow_group(struct fs_node *node)
 	ida_destroy(&fg->fte_allocator);
 	if (ft->autogroup.active)
 		ft->autogroup.num_groups--;
+#if !defined(HAVE_RHLTABLE) && defined(HAVE_NETNS_FRAGS_RHASHTABLE)
+	err = bp_rhltable_remove(&ft->fgs_hash,
+#else
 	err = rhltable_remove(&ft->fgs_hash,
+#endif
 			      &fg->hash,
 			      rhash_fg);
 	WARN_ON(err);
@@ -739,7 +759,11 @@ static struct mlx5_flow_group *alloc_insert_flow_group(struct mlx5_flow_table *f
 		return fg;
 
 	/* initialize refcnt, add to parent list */
+#if !defined(HAVE_RHLTABLE) && defined(HAVE_NETNS_FRAGS_RHASHTABLE)
+	ret = bp_rhltable_insert(&ft->fgs_hash,
+#else
 	ret = rhltable_insert(&ft->fgs_hash,
+#endif
 			      &fg->hash,
 			      rhash_fg);
 	if (ret) {
@@ -769,7 +793,11 @@ static struct mlx5_flow_table *alloc_flow_table(int level, u16 vport, int max_ft
 	if (!ft)
 		return ERR_PTR(-ENOMEM);
 
+#if !defined(HAVE_RHLTABLE) && defined(HAVE_NETNS_FRAGS_RHASHTABLE)
+	ret = bp_rhltable_init(&ft->fgs_hash, &rhash_fg);
+#else
 	ret = rhltable_init(&ft->fgs_hash, &rhash_fg);
+#endif
 	if (ret) {
 		kfree(ft);
 		return ERR_PTR(ret);
@@ -1113,7 +1141,9 @@ static struct mlx5_flow_table *__mlx5_create_flow_table(struct mlx5_flow_namespa
 	fs_prio->num_ft++;
 	up_write_ref_node(&fs_prio->node, false);
 	mutex_unlock(&root->chain_lock);
+#ifndef MLX_DISABLE_TRACEPOINTS
 	trace_mlx5_fs_add_ft(ft);
+#endif
 	return ft;
 destroy_ft:
 	root->cmds->destroy_flow_table(root, ft);
@@ -1217,7 +1247,9 @@ struct mlx5_flow_group *mlx5_create_flow_group(struct mlx5_flow_table *ft,
 		tree_put_node(&fg->node, false);
 		return ERR_PTR(err);
 	}
-	trace_mlx5_fs_add_fg(fg);
+#ifndef MLX_DISABLE_TRACEPOINTS
+       trace_mlx5_fs_add_fg(fg);
+#endif
 	fg->node.active = true;
 
 	return fg;
@@ -1456,7 +1488,9 @@ static int create_auto_flow_group(struct mlx5_flow_table *ft,
 	err = root->cmds->create_flow_group(root, ft, in, fg);
 	if (!err) {
 		fg->node.active = true;
+#ifndef MLX_DISABLE_TRACEPOINTS
 		trace_mlx5_fs_add_fg(fg);
+#endif
 	}
 
 	kvfree(in);
@@ -1650,14 +1684,18 @@ static struct mlx5_flow_handle *add_rule_fg(struct mlx5_flow_group *fg,
 		fte->action.action = old_action;
 		return handle;
 	}
+#ifndef MLX_DISABLE_TRACEPOINTS
 	trace_mlx5_fs_set_fte(fte, false);
+#endif
 
 	for (i = 0; i < handle->num_rules; i++) {
 		if (refcount_read(&handle->rule[i]->node.refcount) == 1) {
 			dest_name = get_dest_name(&handle->rule[i]->dest_attr);
 			tree_add_node(&handle->rule[i]->node, &fte->node, dest_name);
 			kfree(dest_name);
+#ifndef MLX_DISABLE_TRACEPOINTS
 			trace_mlx5_fs_add_rule(handle->rule[i]);
+#endif
 			notify_add_rule(handle->rule[i]);
 		}
 	}
@@ -1717,16 +1755,26 @@ static int build_match_list(struct match_list_head *match_head,
 			    struct mlx5_flow_table *ft,
 			    struct mlx5_flow_spec *spec)
 {
+#if !defined(HAVE_RHLTABLE) && defined(HAVE_NETNS_FRAGS_RHASHTABLE)
+	struct bp_rhlist_head *tmp, *list;
+#else
 	struct rhlist_head *tmp, *list;
+#endif
 	struct mlx5_flow_group *g;
 	int err = 0;
 
 	rcu_read_lock();
 	INIT_LIST_HEAD(&match_head->list);
 	/* Collect all fgs which has a matching match_criteria */
+#if !defined(HAVE_RHLTABLE) && defined(HAVE_NETNS_FRAGS_RHASHTABLE)
+	list = bp_rhltable_lookup(&ft->fgs_hash, spec, rhash_fg);
+	/* RCU is atomic, we can't execute FW commands here */
+	bp_rhl_for_each_entry_rcu(g, tmp, list, hash) {
+#else
 	list = rhltable_lookup(&ft->fgs_hash, spec, rhash_fg);
 	/* RCU is atomic, we can't execute FW commands here */
 	rhl_for_each_entry_rcu(g, tmp, list, hash) {
+#endif
 		struct match_list *curr_match;
 
 		if (likely(list_empty(&match_head->list))) {
@@ -1824,6 +1872,9 @@ try_add_to_existing_fg(struct mlx5_flow_table *ft,
 search_again_locked:
 	version = matched_fgs_get_version(match_head);
 	if (flow_act->flags & FLOW_ACT_NO_APPEND)
+#ifndef HAVE_TC_CLS_OFFLOAD_HANDLE
+		goto skip_search;
+#else
 		list_for_each_entry(iter, match_head, list) {
 			struct fs_fte *fte_tmp;
 
@@ -1841,7 +1892,7 @@ search_again_locked:
 			tree_put_node(&fte_tmp->node, false);
 			goto skip_search;
 		}
-
+#endif
 	/* Try to find a fg that already contains a matching fte */
 	list_for_each_entry(iter, match_head, list) {
 		struct fs_fte *fte_tmp;
@@ -2710,6 +2761,10 @@ void mlx5_cleanup_fs(struct mlx5_core_dev *dev)
 	fs_debugfs_cleanup(dev);
 	kmem_cache_destroy(steering->ftes_cache);
 	kmem_cache_destroy(steering->fgs_cache);
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(3,6,11))
+	kfree(steering->ftes_cache_name);
+	kfree(steering->fgs_cache_name);
+#endif
 	kfree(steering);
 }
 
@@ -2984,6 +3039,10 @@ int mlx5_init_fs(struct mlx5_core_dev *dev)
 	steering->dev = dev;
 	dev->priv.steering = steering;
 
+#if (LINUX_VERSION_CODE <= KERNEL_VERSION(3,6,11))
+	steering->ftes_cache_name = ftes_cache_name;
+	steering->fgs_cache_name = fgs_cache_name;
+#endif
 	snprintf(ftes_cache_name, CACHE_SIZE_NAME, "fs_ftes_%s", dev_name(dev->device));
 	snprintf(fgs_cache_name, CACHE_SIZE_NAME, "fs_fgs_%s", dev_name(dev->device));
 	steering->fgs_cache = kmem_cache_create(fgs_cache_name,
@@ -3053,12 +3112,16 @@ int mlx5_init_fs(struct mlx5_core_dev *dev)
 			goto err;
 	}
 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(3,6,11))
 	kfree(ftes_cache_name);
 	kfree(fgs_cache_name);
+#endif
 	return 0;
 err:
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(3,6,11))
 	kfree(ftes_cache_name);
 	kfree(fgs_cache_name);
+#endif
 	mlx5_cleanup_fs(dev);
 	return err;
 }
