From: Talat Batheesh <talatb@mellanox.com>
Subject: [PATCH] BACKPORT: drivers/net/ethernet/mellanox/mlx5/core/en_rep.c

Change-Id: I7773179de243537849679e4b224d7567b1602294
---
 drivers/net/ethernet/mellanox/mlx5/core/en_rep.c | 596 ++++++++++++++++++++++-
 1 file changed, 574 insertions(+), 22 deletions(-)

diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c b/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
index xxxxxxx..xxxxxxx 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
@@ -30,13 +30,18 @@
  * SOFTWARE.
  */
 
+#ifdef HAVE_UTSRELEASE_H
 #include <generated/utsrelease.h>
+#endif
 #include <linux/mlx5/fs.h>
 #include <net/switchdev.h>
 #include <net/pkt_cls.h>
+#ifdef HAVE_TC_SETUP_CB_EGDEV_REGISTER
 #include <net/act_api.h>
+#endif
 #include <net/netevent.h>
 #include <net/arp.h>
+#include <net/addrconf.h>
 
 #include "lib/devcom.h"
 #include "eswitch.h"
@@ -47,7 +52,9 @@
 #include "fs_core.h"
 #include "ecpf.h"
 #include "lib/port_tun.h"
+#ifdef HAVE_TC_FLOWER_OFFLOAD
 #include "miniflow.h"
+#endif
 
 #define MLX5E_REP_PARAMS_DEF_LOG_SQ_SIZE \
         max(0x7, MLX5E_PARAMS_MINIMUM_LOG_SQ_SIZE)
@@ -65,6 +72,7 @@ struct mlx5e_rep_indr_block_priv {
 static void mlx5e_rep_indr_unregister_block(struct mlx5e_rep_priv *rpriv,
 					    struct net_device *netdev);
 
+#ifdef HAVE_UTSRELEASE_H
 static void mlx5e_rep_get_drvinfo(struct net_device *dev,
 				  struct ethtool_drvinfo *drvinfo)
 {
@@ -89,6 +97,7 @@ static void mlx5e_uplink_rep_get_drvinfo(struct net_device *dev,
 	strlcpy(drvinfo->bus_info, pci_name(priv->mdev->pdev),
 		sizeof(drvinfo->bus_info));
 }
+#endif
 
 static void _mlx5e_get_strings(struct net_device *dev, u32 stringset,
 			       uint8_t *data,
@@ -240,6 +249,7 @@ static int mlx5e_rep_set_ringparam(struct net_device *dev,
 	return mlx5e_ethtool_set_ringparam(priv, param);
 }
 
+#if defined(HAVE_GET_SET_CHANNELS) || defined(HAVE_GET_SET_CHANNELS_EXT)
 static void mlx5e_rep_get_channels(struct net_device *dev,
 				   struct ethtool_channels *ch)
 {
@@ -255,6 +265,7 @@ static int mlx5e_rep_set_channels(struct net_device *dev,
 
 	return mlx5e_ethtool_set_channels(priv, ch);
 }
+#endif
 
 static int mlx5e_rep_get_coalesce(struct net_device *netdev,
 				  struct ethtool_coalesce *coal)
@@ -272,19 +283,23 @@ static int mlx5e_rep_set_coalesce(struct net_device *netdev,
 	return mlx5e_ethtool_set_coalesce(priv, coal);
 }
 
+#if defined(HAVE_GET_SET_RXFH) && !defined(HAVE_GET_SET_RXFH_INDIR_EXT)
 static u32 mlx5e_rep_get_rxfh_key_size(struct net_device *netdev)
 {
 	struct mlx5e_priv *priv = netdev_priv(netdev);
 
 	return mlx5e_ethtool_get_rxfh_key_size(priv);
 }
+#endif
 
+#if defined(HAVE_RXFH_INDIR_SIZE) || defined(HAVE_RXFH_INDIR_SIZE_EXT)
 static u32 mlx5e_rep_get_rxfh_indir_size(struct net_device *netdev)
 {
 	struct mlx5e_priv *priv = netdev_priv(netdev);
 
 	return mlx5e_ethtool_get_rxfh_indir_size(priv);
 }
+#endif
 
 static void mlx5e_uplink_rep_get_pauseparam(struct net_device *netdev,
 					    struct ethtool_pauseparam *pauseparam)
@@ -302,6 +317,7 @@ static int mlx5e_uplink_rep_set_pauseparam(struct net_device *netdev,
 	return mlx5e_ethtool_set_pauseparam(priv, pauseparam);
 }
 
+#ifdef HAVE_GET_SET_LINK_KSETTINGS
 static int mlx5e_uplink_rep_get_link_ksettings(struct net_device *netdev,
 					       struct ethtool_link_ksettings *link_ksettings)
 {
@@ -317,55 +333,119 @@ static int mlx5e_uplink_rep_set_link_ksettings(struct net_device *netdev,
 
 	return mlx5e_ethtool_set_link_ksettings(priv, link_ksettings);
 }
+#endif
 
 static const struct ethtool_ops mlx5e_rep_ethtool_ops = {
+#ifdef HAVE_UTSRELEASE_H
 	.get_drvinfo	   = mlx5e_rep_get_drvinfo,
+#endif
 	.get_link	   = ethtool_op_get_link,
 	.get_strings       = mlx5e_rep_get_strings,
 	.get_sset_count    = mlx5e_rep_get_sset_count,
 	.get_ethtool_stats = mlx5e_rep_get_ethtool_stats,
+#ifdef HAVE_GET_SET_LINK_KSETTINGS
 	.get_link_ksettings  = mlx5e_get_link_ksettings,
 	.set_link_ksettings  = mlx5e_set_link_ksettings,
+#endif
 	.get_ringparam     = mlx5e_rep_get_ringparam,
 	.set_ringparam     = mlx5e_rep_set_ringparam,
+#ifdef HAVE_GET_SET_CHANNELS
 	.get_channels      = mlx5e_rep_get_channels,
 	.set_channels      = mlx5e_rep_set_channels,
+#endif
 	.get_coalesce      = mlx5e_rep_get_coalesce,
 	.set_coalesce      = mlx5e_rep_set_coalesce,
+#if defined(HAVE_GET_SET_RXFH) && !defined(HAVE_GET_SET_RXFH_INDIR_EXT)
 	.get_rxfh_key_size   = mlx5e_rep_get_rxfh_key_size,
+#endif
+#if defined(HAVE_RXFH_INDIR_SIZE) && !defined(HAVE_RXFH_INDIR_SIZE_EXT)
 	.get_rxfh_indir_size = mlx5e_rep_get_rxfh_indir_size,
+#endif
+#ifdef HAVE_GET_SET_PRIV_FLAGS
 	.get_priv_flags    = mlx5e_get_priv_flags,
 	.set_priv_flags    = mlx5e_set_priv_flags,
-};
+#endif
+ };
 
 static const struct ethtool_ops mlx5e_uplink_rep_ethtool_ops = {
+#ifdef HAVE_UTSRELEASE_H
 	.get_drvinfo	   = mlx5e_uplink_rep_get_drvinfo,
+#endif
 	.get_link	   = ethtool_op_get_link,
 	.get_strings       = mlx5e_ul_rep_get_strings,
 	.get_sset_count    = mlx5e_ul_rep_get_sset_count,
 	.get_ethtool_stats = mlx5e_ul_rep_get_ethtool_stats,
 	.get_ringparam     = mlx5e_rep_get_ringparam,
 	.set_ringparam     = mlx5e_rep_set_ringparam,
+#ifdef HAVE_GET_SET_CHANNELS
 	.get_channels      = mlx5e_rep_get_channels,
 	.set_channels      = mlx5e_rep_set_channels,
+#endif
 	.get_coalesce      = mlx5e_rep_get_coalesce,
 	.set_coalesce      = mlx5e_rep_set_coalesce,
+#ifdef HAVE_GET_SET_LINK_KSETTINGS
 	.get_link_ksettings = mlx5e_uplink_rep_get_link_ksettings,
 	.set_link_ksettings = mlx5e_uplink_rep_set_link_ksettings,
-	.get_rxfh_key_size   = mlx5e_rep_get_rxfh_key_size,
+#endif
+#ifdef HAVE_ETHTOOL_GET_SET_SETTINGS
+	.get_settings  = mlx5e_get_settings,
+	.set_settings  = mlx5e_set_settings,
+#endif
+#if defined(HAVE_RXFH_INDIR_SIZE) && !defined(HAVE_RXFH_INDIR_SIZE_EXT)
 	.get_rxfh_indir_size = mlx5e_rep_get_rxfh_indir_size,
+#endif
+#ifndef HAVE_GET_SET_RXFH_INDIR_EXT
+#ifdef HAVE_GET_SET_RXFH
+	.get_rxfh_key_size   = mlx5e_rep_get_rxfh_key_size,
 	.get_rxfh          = mlx5e_get_rxfh,
 	.set_rxfh          = mlx5e_set_rxfh,
+#elif defined(HAVE_GET_SET_RXFH_INDIR)
+	.get_rxfh_indir    = mlx5e_get_rxfh_indir,
+	.set_rxfh_indir    = mlx5e_set_rxfh_indir,
+#endif
+#endif
 #ifdef CONFIG_MLX5_EN_RXNFC
 	.get_rxnfc         = mlx5e_get_rxnfc,
 	.set_rxnfc         = mlx5e_set_rxnfc,
 #endif
 	.get_pauseparam    = mlx5e_uplink_rep_get_pauseparam,
 	.set_pauseparam    = mlx5e_uplink_rep_set_pauseparam,
+#ifdef HAVE_GET_SET_PRIV_FLAGS
 	.get_priv_flags    = mlx5e_get_priv_flags,
 	.set_priv_flags    = mlx5e_set_priv_flags,
+#endif
 };
 
+#ifdef HAVE_ETHTOOL_OPS_EXT
+static const struct ethtool_ops_ext mlx5e_rep_ethtool_ops_ext = {
+	.size		   = sizeof(struct ethtool_ops_ext),
+#ifdef HAVE_GET_SET_CHANNELS_EXT
+	.get_channels      = mlx5e_rep_get_channels,
+	.set_channels      = mlx5e_rep_set_channels,
+#endif
+#ifdef HAVE_RXFH_INDIR_SIZE_EXT
+	.get_rxfh_indir_size = mlx5e_rep_get_rxfh_indir_size,
+#endif
+ };
+ 
+static const struct ethtool_ops_ext mlx5e_uplink_rep_ethtool_ops_ext = {
+	.size		   = sizeof(struct ethtool_ops_ext),
+#ifdef HAVE_GET_SET_CHANNELS_EXT
+	.get_channels      = mlx5e_rep_get_channels,
+	.set_channels      = mlx5e_rep_set_channels,
+#endif
+#ifdef HAVE_RXFH_INDIR_SIZE_EXT
+	.get_rxfh_indir_size = mlx5e_rep_get_rxfh_indir_size,
+#endif
+#ifdef HAVE_GET_SET_RXFH_INDIR_EXT
+	.get_rxfh_indir    = mlx5e_get_rxfh_indir,
+	.set_rxfh_indir    = mlx5e_set_rxfh_indir,
+#endif
+};
+#endif
+
+
+#if defined(HAVE_DEVLINK_HEALTH_REPORT) || defined(HAVE_SWITCHDEV_OPS)
 static int mlx5e_rep_get_port_parent_id(struct net_device *dev,
 					struct netdev_phys_item_id *ppid)
 {
@@ -385,6 +465,7 @@ static int mlx5e_rep_get_port_parent_id(struct net_device *dev,
 
 	return 0;
 }
+#endif
 
 static void mlx5e_sqs2vport_stop(struct mlx5_eswitch *esw,
 				 struct mlx5_eswitch_rep *rep)
@@ -513,11 +594,13 @@ void mlx5e_remove_sqs_fwd_rules(struct mlx5e_priv *priv)
 	mlx5e_sqs2vport_stop(esw, rep);
 }
 
+#ifdef HAVE_TCF_TUNNEL_INFO
 static void mlx5e_rep_neigh_update_init_interval(struct mlx5e_rep_priv *rpriv)
 {
 #if IS_ENABLED(CONFIG_IPV6)
-	unsigned long ipv6_interval = NEIGH_VAR(&nd_tbl.parms,
-						DELAY_PROBE_TIME);
+	unsigned long ipv6_interval = (ipv6_stub && ipv6_stub->nd_tbl) ?
+				      NEIGH_VAR(&ipv6_stub->nd_tbl->parms,
+						DELAY_PROBE_TIME) : ~0UL;
 #else
 	unsigned long ipv6_interval = ~0UL;
 #endif
@@ -686,6 +769,8 @@ static void mlx5e_rep_neigh_update(struct work_struct *work)
 	neigh_release(n);
 }
 
+#ifdef CONFIG_MLX5_ESWITCH
+#ifdef HAVE_TC_BLOCK_OFFLOAD
 static struct mlx5e_rep_indr_block_priv *
 mlx5e_rep_indr_block_priv_lookup(struct mlx5e_rep_priv *rpriv,
 				 struct net_device *netdev)
@@ -703,6 +788,8 @@ mlx5e_rep_indr_block_priv_lookup(struct mlx5e_rep_priv *rpriv,
 
 	return NULL;
 }
+#endif
+#endif
 
 static void mlx5e_rep_indr_clean_block_privs(struct mlx5e_rep_priv *rpriv)
 {
@@ -715,6 +802,7 @@ static void mlx5e_rep_indr_clean_block_privs(struct mlx5e_rep_priv *rpriv)
 	}
 }
 
+#ifdef HAVE_TC_BLOCK_OFFLOAD
 static int
 mlx5e_rep_indr_offload(struct net_device *netdev,
 		       struct tc_cls_flower_offload *flower,
@@ -740,7 +828,6 @@ mlx5e_rep_indr_offload(struct net_device *netdev,
 
 	return err;
 }
-
 static int mlx5e_rep_indr_setup_block_cb(enum tc_setup_type type,
 					 void *type_data, void *indr_priv)
 {
@@ -753,7 +840,9 @@ static int mlx5e_rep_indr_setup_block_cb(enum tc_setup_type type,
 		return -EOPNOTSUPP;
 	}
 }
+#endif
 
+#ifdef HAVE_TC_BLOCK_OFFLOAD
 static int
 mlx5e_rep_indr_setup_tc_block(struct net_device *netdev,
 			      struct mlx5e_rep_priv *rpriv,
@@ -782,7 +871,11 @@ mlx5e_rep_indr_setup_tc_block(struct net_device *netdev,
 
 		err = tcf_block_cb_register(f->block,
 					    mlx5e_rep_indr_setup_block_cb,
+#ifdef HAVE_TC_BLOCK_OFFLOAD_EXTACK
 					    indr_priv, indr_priv, f->extack);
+#else
+					    indr_priv, indr_priv);
+#endif
 		if (err) {
 			list_del(&indr_priv->list);
 			kfree(indr_priv);
@@ -806,15 +899,20 @@ mlx5e_rep_indr_setup_tc_block(struct net_device *netdev,
 	}
 	return 0;
 }
+#endif
 
 static
 int mlx5e_rep_indr_setup_tc_cb(struct net_device *netdev, void *cb_priv,
 			       enum tc_setup_type type, void *type_data)
 {
 	switch (type) {
+#ifdef CONFIG_MLX5_ESWITCH
+#ifdef HAVE_TC_BLOCK_OFFLOAD
 	case TC_SETUP_BLOCK:
 		return mlx5e_rep_indr_setup_tc_block(netdev, cb_priv,
 						      type_data);
+#endif
+#endif
 	default:
 		return -EOPNOTSUPP;
 	}
@@ -898,27 +996,37 @@ static int mlx5e_rep_netevent_event(struct notifier_block *nb,
 {
 	struct mlx5e_rep_priv *rpriv = container_of(nb, struct mlx5e_rep_priv,
 						    neigh_update.netevent_nb);
+#ifdef NETEVENT_DELAY_PROBE_TIME_UPDATE
 	struct mlx5e_neigh_update_table *neigh_update = &rpriv->neigh_update;
+#endif
 	struct net_device *netdev = rpriv->netdev;
 	struct mlx5e_priv *priv = netdev_priv(netdev);
 	struct mlx5e_neigh_hash_entry *nhe = NULL;
 	struct mlx5e_neigh m_neigh = {};
+#ifdef NETEVENT_DELAY_PROBE_TIME_UPDATE
 	struct neigh_parms *p;
+#endif
 	struct neighbour *n;
+#ifdef NETEVENT_DELAY_PROBE_TIME_UPDATE
 	bool found = false;
+#endif
 
 	switch (event) {
 	case NETEVENT_NEIGH_UPDATE:
 		n = ptr;
 #if IS_ENABLED(CONFIG_IPV6)
-		if (n->tbl != &nd_tbl && n->tbl != &arp_tbl)
+		if ((!ipv6_stub || !ipv6_stub->nd_tbl ||
+		     n->tbl != ipv6_stub->nd_tbl) &&
+		     n->tbl != &arp_tbl)
 #else
 		if (n->tbl != &arp_tbl)
 #endif
 			return NOTIFY_DONE;
 
 		m_neigh.dev = n->dev;
+#ifdef HAVE_TCF_TUNNEL_INFO
 		m_neigh.family = n->ops->family;
+#endif
 		memcpy(&m_neigh.dst_ip, n->primary_key, n->tbl->key_len);
 
 		rcu_read_lock();
@@ -930,6 +1038,7 @@ static int mlx5e_rep_netevent_event(struct notifier_block *nb,
 		mlx5e_rep_queue_neigh_update_work(priv, nhe, n);
 		break;
 
+#ifdef NETEVENT_DELAY_PROBE_TIME_UPDATE
 	case NETEVENT_DELAY_PROBE_TIME_UPDATE:
 		p = ptr;
 
@@ -938,7 +1047,10 @@ static int mlx5e_rep_netevent_event(struct notifier_block *nb,
 		 * done per device delay prob time parameter.
 		 */
 #if IS_ENABLED(CONFIG_IPV6)
-		if (!p->dev || (p->tbl != &nd_tbl && p->tbl != &arp_tbl))
+		if (!p->dev ||
+		    ((!ipv6_stub || !ipv6_stub->nd_tbl ||
+		      p->tbl != ipv6_stub->nd_tbl) &&
+		    p->tbl != &arp_tbl))
 #else
 		if (!p->dev || p->tbl != &arp_tbl)
 #endif
@@ -962,9 +1074,11 @@ static int mlx5e_rep_netevent_event(struct notifier_block *nb,
 		mlx5_fc_update_sampling_interval(priv->mdev,
 						 neigh_update->min_interval);
 		break;
+#endif
 	}
 	return NOTIFY_DONE;
 }
+#endif /* HAVE_TCF_TUNNEL_INFO */
 
 static const struct rhashtable_params mlx5e_neigh_ht_params = {
 	.head_offset = offsetof(struct mlx5e_neigh_hash_entry, rhash_node),
@@ -983,6 +1097,7 @@ static int mlx5e_rep_neigh_init(struct mlx5e_rep_priv *rpriv)
 		return err;
 
 	INIT_LIST_HEAD(&neigh_update->neigh_list);
+#ifdef HAVE_TCF_TUNNEL_INFO
 	spin_lock_init(&neigh_update->encap_lock);
 	INIT_DELAYED_WORK(&neigh_update->neigh_stats_work,
 			  mlx5e_rep_neigh_stats_work);
@@ -996,12 +1111,14 @@ static int mlx5e_rep_neigh_init(struct mlx5e_rep_priv *rpriv)
 
 out_err:
 	rhashtable_destroy(&neigh_update->neigh_ht);
+#endif
 	return err;
 }
 
 static void mlx5e_rep_neigh_cleanup(struct mlx5e_rep_priv *rpriv)
 {
 	struct mlx5e_neigh_update_table *neigh_update = &rpriv->neigh_update;
+#ifdef HAVE_TCF_TUNNEL_INFO
 	struct mlx5e_priv *priv = netdev_priv(rpriv->netdev);
 
 	unregister_netevent_notifier(&neigh_update->netevent_nb);
@@ -1009,10 +1126,12 @@ static void mlx5e_rep_neigh_cleanup(struct mlx5e_rep_priv *rpriv)
 	flush_workqueue(priv->wq); /* flush neigh update works */
 
 	cancel_delayed_work_sync(&rpriv->neigh_update.neigh_stats_work);
+#endif
 
 	rhashtable_destroy(&neigh_update->neigh_ht);
 }
 
+#ifdef HAVE_TCF_TUNNEL_INFO
 static int mlx5e_rep_neigh_entry_insert(struct mlx5e_priv *priv,
 					struct mlx5e_neigh_hash_entry *nhe)
 {
@@ -1034,14 +1153,18 @@ static void mlx5e_rep_neigh_entry_remove(struct mlx5e_neigh_hash_entry *nhe)
 {
 	struct mlx5e_rep_priv *rpriv = nhe->priv->ppriv;
 
+#ifdef HAVE_TCF_TUNNEL_INFO
 	spin_lock_bh(&rpriv->neigh_update.encap_lock);
+#endif
 
 	list_del_rcu(&nhe->neigh_list);
 
 	rhashtable_remove_fast(&rpriv->neigh_update.neigh_ht,
 			       &nhe->rhash_node,
 			       mlx5e_neigh_ht_params);
+#ifdef HAVE_TCF_TUNNEL_INFO
 	spin_unlock_bh(&rpriv->neigh_update.encap_lock);
+#endif
 }
 
 /* This function must only be called under RTNL lock or under the
@@ -1140,6 +1263,7 @@ void mlx5e_rep_encap_entry_detach(struct mlx5e_priv *priv,
 	e->nhe = NULL;
 	mlx5_tun_entropy_refcount_dec(tun_entropy, e->reformat_type);
 }
+#endif /* HAVE_TCF_TUNNEL_INFO */
 
 static int mlx5e_rep_open(struct net_device *dev)
 {
@@ -1193,6 +1317,7 @@ static u32 get_sf_phys_port_num(const struct mlx5_core_dev *dev, u16 vport_num)
 	return (MLX5_CAP_GEN(dev, vhca_id) << 16) | vport_num;
 }
 
+#if defined(HAVE_NDO_GET_PHYS_PORT_NAME) || defined(HAVE_SWITCHDEV_H_COMPAT) || defined(HAVE_NDO_GET_PHYS_PORT_NAME_EXTENDED)
 static int mlx5e_rep_get_phys_port_name(struct net_device *dev,
 					char *buf, size_t len)
 {
@@ -1220,42 +1345,126 @@ static int mlx5e_rep_get_phys_port_name(struct net_device *dev,
 
 	return 0;
 }
+#endif
 
+#if defined(HAVE_TC_FLOWER_OFFLOAD)
 static int
+#if defined(HAVE_NDO_SETUP_TC_TAKES_TC_SETUP_TYPE) || defined(HAVE_NDO_SETUP_TC_RH_EXTENDED)
+#ifdef HAVE_TC_BLOCK_OFFLOAD
 mlx5e_rep_setup_tc_cls_flower(struct mlx5e_priv *priv,
+#else
+mlx5e_rep_setup_tc_cls_flower(struct net_device *dev,
+#endif
 			      struct tc_cls_flower_offload *cls_flower, int flags)
+#else
+mlx5e_rep_setup_tc_cls_flower(struct net_device *dev,
+			      u32 handle,
+#ifdef HAVE_NDO_SETUP_TC_TAKES_CHAIN_INDEX
+			      u32 chain_index,
+#endif
+			      __be16 proto,
+			      struct tc_to_netdev *tc, int flags)
+#endif
 {
+#if !defined(HAVE_NDO_SETUP_TC_TAKES_TC_SETUP_TYPE) && !defined(HAVE_NDO_SETUP_TC_RH_EXTENDED)
+	struct tc_cls_flower_offload *cls_flower = tc->cls_flower;
+#endif
+	int err;
+
+#ifndef HAVE_TC_CLS_CAN_OFFLOAD_AND_CHAIN0
+#ifdef HAVE_TC_BLOCK_OFFLOAD
+	if (cls_flower->common.chain_index)
+#else
+	struct mlx5e_priv *priv = netdev_priv(dev);
+#if defined(HAVE_NDO_SETUP_TC_TAKES_TC_SETUP_TYPE) || defined(HAVE_NDO_SETUP_TC_RH_EXTENDED)
+	if (!is_classid_clsact_ingress(cls_flower->common.classid) ||
+	    cls_flower->common.chain_index)
+#else
+	if (TC_H_MAJ(handle) != TC_H_MAJ(TC_H_INGRESS) ||
+#ifdef HAVE_NDO_SETUP_TC_TAKES_CHAIN_INDEX
+	    chain_index)
+#else
+	    0)
+#endif
+#endif
+#endif
+		return -EOPNOTSUPP;
+#endif
+
+#if defined(HAVE_TC_TO_NETDEV_EGRESS_DEV) || defined(HAVE_TC_CLS_FLOWER_OFFLOAD_EGRESS_DEV)
+#ifndef HAVE_TC_SETUP_CB_EGDEV_REGISTER
+#if defined(HAVE_NDO_SETUP_TC_TAKES_TC_SETUP_TYPE) || defined(HAVE_NDO_SETUP_TC_RH_EXTENDED)
+	if (cls_flower->egress_dev) {
+#else
+	if (tc->egress_dev) {
+#endif
+		struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
+		struct mlx5e_rep_priv * uplink_rpriv = mlx5_eswitch_get_uplink_priv(esw, REP_ETH);
+		struct net_device *uplink_dev = uplink_rpriv->netdev;
+
+		if (uplink_dev != dev) {
+#if defined(HAVE_NDO_SETUP_TC_TAKES_TC_SETUP_TYPE)
+		err = dev->netdev_ops->ndo_setup_tc(uplink_dev, TC_SETUP_CLSFLOWER,
+						      cls_flower);
+#elif defined(HAVE_NDO_SETUP_TC_RH_EXTENDED)
+		err = dev->netdev_ops->extended.ndo_setup_tc_rh(uplink_dev,
+							 TC_SETUP_CLSFLOWER,
+							 cls_flower);
+
+#else
+		err = dev->netdev_ops->ndo_setup_tc(uplink_dev, handle,
+#ifdef HAVE_NDO_SETUP_TC_TAKES_CHAIN_INDEX
+						      chain_index,
+#endif
+						      proto, tc);
+#endif
+		return err;
+		}
+	 }
+#endif
+#endif
+
 	switch (cls_flower->command) {
 	case TC_CLSFLOWER_REPLACE:
-		return mlx5e_configure_flower(priv->netdev, priv, cls_flower,
+		err = mlx5e_configure_flower(priv->netdev, priv, cls_flower,
 					      flags);
+		return err;
 	case TC_CLSFLOWER_DESTROY:
-		return mlx5e_delete_flower(priv->netdev, priv, cls_flower,
+		err = mlx5e_delete_flower(priv->netdev, priv, cls_flower,
 					   flags);
+		return err;
+#ifdef HAVE_TC_CLSFLOWER_STATS
 	case TC_CLSFLOWER_STATS:
-		return mlx5e_stats_flower(priv->netdev, priv, cls_flower,
+		err = mlx5e_stats_flower(priv->netdev, priv, cls_flower,
 					  flags);
+		return err;
+#endif
 	default:
 		return -EOPNOTSUPP;
 	}
 }
-
-#ifdef HAVE_MINIFLOW
+#endif /* defined(HAVE_TC_FLOWER_OFFLOAD) */
+ 
+#ifdef HAVE_TC_BLOCK_OFFLOAD
 static int mlx5e_rep_setup_tc_cb_egdev(enum tc_setup_type type, void *type_data,
 				       void *cb_priv)
 {
+	unsigned long flags = MLX5_TC_FLAG(EGRESS) | MLX5_TC_FLAG(ESW_OFFLOAD);
 	struct mlx5e_priv *priv = cb_priv;
 
 	switch (type) {
+	case TC_SETUP_CLSFLOWER:
+		return mlx5e_rep_setup_tc_cls_flower(priv, type_data, flags);
+#ifdef HAVE_MINIFLOW
 	case TC_SETUP_MINIFLOW:
 		return miniflow_configure(priv, type_data);
 	case TC_SETUP_CT:
 		return miniflow_configure_ct(priv, type_data);
+#endif
 	default:
 		return -EOPNOTSUPP;
 	}
 }
-#endif
 
 static int mlx5e_rep_setup_tc_cb(enum tc_setup_type type, void *type_data,
 				 void *cb_priv)
@@ -1288,7 +1497,12 @@ static int mlx5e_rep_setup_tc_block(struct net_device *dev,
 	switch (f->command) {
 	case TC_BLOCK_BIND:
 		return tcf_block_cb_register(f->block, mlx5e_rep_setup_tc_cb,
+#ifdef HAVE_TC_BLOCK_OFFLOAD_EXTACK
 					     priv, priv, f->extack);
+#else
+
+					     priv, priv);
+#endif
 	case TC_BLOCK_UNBIND:
 		tcf_block_cb_unregister(f->block, mlx5e_rep_setup_tc_cb, priv);
 		return 0;
@@ -1296,17 +1510,60 @@ static int mlx5e_rep_setup_tc_block(struct net_device *dev,
 		return -EOPNOTSUPP;
 	}
 }
+#endif /* HAVE_TC_BLOCK_OFFLOAD */
 
+#if defined(HAVE_TC_FLOWER_OFFLOAD)
+#if defined(HAVE_NDO_SETUP_TC_TAKES_TC_SETUP_TYPE) || defined(HAVE_NDO_SETUP_TC_RH_EXTENDED)
 static int mlx5e_rep_setup_tc(struct net_device *dev, enum tc_setup_type type,
 			      void *type_data)
+#else
+static int mlx5e_rep_setup_tc(struct net_device *dev, u32 handle,
+#ifdef HAVE_NDO_SETUP_TC_TAKES_CHAIN_INDEX
+			      u32 chain_index, __be16 proto,
+#else
+			      __be16 proto,
+#endif
+			      struct tc_to_netdev *tc)
+#endif
 {
+#if !defined(HAVE_NDO_SETUP_TC_TAKES_TC_SETUP_TYPE) && !defined(HAVE_NDO_SETUP_TC_RH_EXTENDED)
+	unsigned int type = tc->type;
+#endif
+#ifndef HAVE_TC_BLOCK_OFFLOAD
+	unsigned long flags = MLX5_TC_FLAG(INGRESS) | MLX5_TC_FLAG(ESW_OFFLOAD);
+#endif
+
 	switch (type) {
+#ifdef HAVE_TC_BLOCK_OFFLOAD
 	case TC_SETUP_BLOCK:
 		return mlx5e_rep_setup_tc_block(dev, type_data);
+#else
+	case TC_SETUP_CLSFLOWER:
+#if defined(HAVE_NDO_SETUP_TC_TAKES_TC_SETUP_TYPE) || defined(HAVE_NDO_SETUP_TC_RH_EXTENDED)
+		return mlx5e_rep_setup_tc_cls_flower(dev, type_data, flags);
+#else
+		return mlx5e_rep_setup_tc_cls_flower(dev, handle,
+#ifdef HAVE_NDO_SETUP_TC_TAKES_CHAIN_INDEX
+						     chain_index,
+#endif
+						     proto, tc, flags);
+#endif
+#endif
 	default:
 		return -EOPNOTSUPP;
 	}
 }
+#endif
+
+#if !defined(HAVE_TC_BLOCK_OFFLOAD) && defined(HAVE_TC_SETUP_CB_EGDEV_REGISTER)
+static int mlx5e_rep_setup_tc_cb(enum tc_setup_type type, void *type_data,
+				 void *cb_priv)
+{
+	struct net_device *dev = cb_priv;
+
+	return mlx5e_setup_tc(dev, type, type_data);
+}
+#endif
 
 bool mlx5e_is_uplink_rep(struct mlx5e_priv *priv)
 {
@@ -1323,6 +1580,7 @@ bool mlx5e_is_uplink_rep(struct mlx5e_priv *priv)
 	return (rep->vport == MLX5_VPORT_UPLINK);
 }
 
+#if defined(NDO_HAS_OFFLOAD_STATS_GETS_NET_DEVICE) || defined(HAVE_NDO_HAS_OFFLOAD_STATS_EXTENDED)
 static bool mlx5e_rep_has_offload_stats(const struct net_device *dev, int attr_id)
 {
 	switch (attr_id) {
@@ -1332,7 +1590,9 @@ static bool mlx5e_rep_has_offload_stats(const struct net_device *dev, int attr_i
 
 	return false;
 }
+#endif
 
+#if defined(HAVE_NDO_GET_OFFLOAD_STATS) || defined(HAVE_NDO_GET_OFFLOAD_STATS_EXTENDED)
 static int
 mlx5e_get_sw_stats64(const struct net_device *dev,
 		     struct rtnl_link_stats64 *stats)
@@ -1355,15 +1615,29 @@ static int mlx5e_rep_get_offload_stats(int attr_id, const struct net_device *dev
 
 	return -EINVAL;
 }
+#endif /* defined(HAVE_NDO_GET_OFFLOAD_STATS) || defined(HAVE_NDO_GET_OFFLOAD_STATS_EXTENDED) */
 
-static void
-mlx5e_rep_get_stats(struct net_device *dev, struct rtnl_link_stats64 *stats)
+static
+#ifdef HAVE_NDO_GET_STATS64_RET_VOID
+void mlx5e_rep_get_stats(struct net_device *dev, struct rtnl_link_stats64 *stats)
+#elif defined(HAVE_NDO_GET_STATS64)
+struct rtnl_link_stats64 * mlx5e_rep_get_stats(struct net_device *dev, struct rtnl_link_stats64 *stats)
+#else
+struct net_device_stats * mlx5e_rep_get_stats(struct net_device *dev)
+#endif
 {
 	struct mlx5e_priv *priv = netdev_priv(dev);
+#if !defined(HAVE_NDO_GET_STATS64) && !defined(HAVE_NDO_GET_STATS64_RET_VOID)
+	struct net_device_stats *stats = &priv->netdev_stats;
+#endif
 
 	/* update HW stats in background for next time */
 	mlx5e_queue_update_stats(priv);
 	memcpy(stats, &priv->stats.vf_vport, sizeof(*stats));
+
+#ifndef HAVE_NDO_GET_STATS64_RET_VOID
+	return stats;
+#endif
 }
 
 static int mlx5e_rep_change_mtu(struct net_device *netdev, int new_mtu)
@@ -1387,8 +1661,12 @@ static int mlx5e_uplink_rep_set_mac(struct net_device *netdev, void *addr)
 	return 0;
 }
 
+#ifdef HAVE_VF_VLAN_PROTO
 static int mlx5e_uplink_rep_set_vf_vlan(struct net_device *dev, int vf, u16 vlan, u8 qos,
 					__be16 vlan_proto)
+#else
+static int mlx5e_uplink_rep_set_vf_vlan(struct net_device *dev, int vf, u16 vlan, u8 qos)
+#endif
 {
 	netdev_warn_once(dev, "legacy vf vlan setting isn't supported in switchdev mode\n");
 
@@ -1403,13 +1681,44 @@ static const struct net_device_ops mlx5e_netdev_ops_rep = {
 	.ndo_open                = mlx5e_rep_open,
 	.ndo_stop                = mlx5e_rep_close,
 	.ndo_start_xmit          = mlx5e_xmit,
+#ifdef HAVE_NET_DEVICE_OPS_EXTENDED
+	.ndo_size                = sizeof(struct net_device_ops),
+#endif
+#ifdef HAVE_NDO_GET_PHYS_PORT_NAME
 	.ndo_get_phys_port_name  = mlx5e_rep_get_phys_port_name,
+#elif defined(HAVE_NDO_GET_PHYS_PORT_NAME_EXTENDED)
+	.extended.ndo_get_phys_port_name = mlx5e_rep_get_phys_port_name,
+#endif
+#if defined(HAVE_TC_FLOWER_OFFLOAD)
+#ifdef HAVE_NDO_SETUP_TC_RH_EXTENDED
+	.extended.ndo_setup_tc_rh = mlx5e_rep_setup_tc,
+#else
 	.ndo_setup_tc            = mlx5e_rep_setup_tc,
+#endif
+#endif
+#if defined(HAVE_NDO_GET_STATS64) || defined(HAVE_NDO_GET_STATS64_RET_VOID)
 	.ndo_get_stats64         = mlx5e_rep_get_stats,
+#else
+	.ndo_get_stats           = mlx5e_rep_get_stats,
+#endif
+#ifdef NDO_HAS_OFFLOAD_STATS_GETS_NET_DEVICE
 	.ndo_has_offload_stats	 = mlx5e_rep_has_offload_stats,
+#elif defined(HAVE_NDO_HAS_OFFLOAD_STATS_EXTENDED)
+	.extended.ndo_has_offload_stats   = mlx5e_rep_has_offload_stats,
+#endif
+#ifdef HAVE_NDO_GET_OFFLOAD_STATS
 	.ndo_get_offload_stats	 = mlx5e_rep_get_offload_stats,
+#elif defined(HAVE_NDO_GET_OFFLOAD_STATS_EXTENDED)
+	.extended.ndo_get_offload_stats   = mlx5e_rep_get_offload_stats,
+#endif
+#ifdef HAVE_NDO_CHANGE_MTU_EXTENDED
+	.extended.ndo_change_mtu = mlx5e_rep_change_mtu,
+#else
 	.ndo_change_mtu          = mlx5e_rep_change_mtu,
+#endif
+#ifdef HAVE_DEVLINK_HEALTH_REPORT
 	.ndo_get_port_parent_id	 = mlx5e_rep_get_port_parent_id,
+#endif
 };
 
 static const struct net_device_ops mlx5e_netdev_ops_uplink_rep = {
@@ -1417,21 +1726,84 @@ static const struct net_device_ops mlx5e_netdev_ops_uplink_rep = {
 	.ndo_stop                = mlx5e_close,
 	.ndo_start_xmit          = mlx5e_xmit,
 	.ndo_set_mac_address     = mlx5e_uplink_rep_set_mac,
+#ifdef HAVE_NET_DEVICE_OPS_EXTENDED
+	.ndo_size                = sizeof(struct net_device_ops),
+#endif
+#ifdef HAVE_NDO_GET_PHYS_PORT_NAME
 	.ndo_get_phys_port_name  = mlx5e_rep_get_phys_port_name,
+#elif defined(HAVE_NDO_GET_PHYS_PORT_NAME_EXTENDED)
+	.extended.ndo_get_phys_port_name = mlx5e_rep_get_phys_port_name,
+#endif
+#if defined(HAVE_TC_FLOWER_OFFLOAD)
+#ifdef HAVE_NDO_SETUP_TC_RH_EXTENDED
+	.extended.ndo_setup_tc_rh = mlx5e_rep_setup_tc,
+#else
 	.ndo_setup_tc            = mlx5e_rep_setup_tc,
+#endif
+#endif
+#if defined(HAVE_NDO_GET_STATS64) || defined(HAVE_NDO_GET_STATS64_RET_VOID)
 	.ndo_get_stats64         = mlx5e_get_stats,
+#else
+	.ndo_get_stats           = mlx5e_get_stats,
+#endif
+#ifdef NDO_HAS_OFFLOAD_STATS_GETS_NET_DEVICE
 	.ndo_has_offload_stats	 = mlx5e_rep_has_offload_stats,
+#elif defined(HAVE_NDO_HAS_OFFLOAD_STATS_EXTENDED)
+	.extended.ndo_has_offload_stats   = mlx5e_rep_has_offload_stats,
+#endif
+#ifdef HAVE_NDO_GET_OFFLOAD_STATS
 	.ndo_get_offload_stats	 = mlx5e_rep_get_offload_stats,
+#elif defined(HAVE_NDO_GET_OFFLOAD_STATS_EXTENDED)
+	.extended.ndo_get_offload_stats   = mlx5e_rep_get_offload_stats,
+#endif
+#ifdef HAVE_NDO_CHANGE_MTU_EXTENDED
+	.extended.ndo_change_mtu = mlx5e_uplink_rep_change_mtu,
+#else
 	.ndo_change_mtu          = mlx5e_uplink_rep_change_mtu,
+#endif
+
+#ifdef HAVE_KERNEL_WITH_VXLAN_SUPPORT_ON
+#ifdef HAVE_NDO_UDP_TUNNEL_ADD
 	.ndo_udp_tunnel_add      = mlx5e_add_vxlan_port,
 	.ndo_udp_tunnel_del      = mlx5e_del_vxlan_port,
+#elif defined(HAVE_NDO_UDP_TUNNEL_ADD_EXTENDED)
+	.extended.ndo_udp_tunnel_add = mlx5e_add_vxlan_port,
+	.extended.ndo_udp_tunnel_del = mlx5e_del_vxlan_port,
+#elif defined(HAVE_NDO_ADD_VXLAN_PORT)
+	.ndo_add_vxlan_port	 = mlx5e_add_vxlan_port,
+	.ndo_del_vxlan_port	 = mlx5e_del_vxlan_port,
+#endif
+#endif
+#ifdef HAVE_NETDEV_FEATURES_T
 	.ndo_features_check      = mlx5e_features_check,
+#elif defined(HAVE_KERNEL_WITH_VXLAN_SUPPORT_ON) && defined(HAVE_VXLAN_GSO_CHECK)
+	.ndo_gso_check           = mlx5e_gso_check,
+#endif
+
+#ifdef HAVE_NDO_SET_VF_MAC
 	.ndo_set_vf_mac          = mlx5e_set_vf_mac,
+#endif
+#ifdef HAVE_NDO_SET_VF_MAC
+#ifdef HAVE_VF_TX_RATE_LIMITS
 	.ndo_set_vf_rate         = mlx5e_set_vf_rate,
+#else
+	.ndo_set_vf_tx_rate      = mlx5e_set_vf_rate,
+#endif
+#endif
+#ifdef HAVE_NDO_SET_VF_MAC
 	.ndo_get_vf_config       = mlx5e_get_vf_config,
+#endif
+#ifdef HAVE_NDO_GET_VF_STATS
 	.ndo_get_vf_stats        = mlx5e_get_vf_stats,
+#endif
+#if defined(HAVE_NDO_SET_VF_VLAN)
 	.ndo_set_vf_vlan         = mlx5e_uplink_rep_set_vf_vlan,
+#elif defined(HAVE_NDO_SET_VF_VLAN_EXTENDED)
+	.extended.ndo_set_vf_vlan  = mlx5e_uplink_rep_set_vf_vlan,
+#endif
+#ifdef HAVE_DEVLINK_HEALTH_REPORT
 	.ndo_get_port_parent_id	 = mlx5e_rep_get_port_parent_id,
+#endif
 	.ndo_set_features        = mlx5e_set_features,
 };
 
@@ -1480,10 +1852,33 @@ static void mlx5e_build_rep_params(struct net_device *netdev)
 
 	MLX5E_SET_PFLAG(params, MLX5E_PFLAG_PER_CH_STATS, true);
 
+#ifdef HAVE_ETH_SS_RSS_HASH_FUNCS
 	/* RSS */
 	mlx5e_build_rss_params(&priv->rss_params, params->num_channels);
+#endif
+}
+
+#ifdef HAVE_SWITCHDEV_OPS
+int mlx5e_attr_get(struct net_device *dev, struct switchdev_attr *attr)
+{
+    int err = 0;
+
+    switch (attr->id) {
+    case SWITCHDEV_ATTR_ID_PORT_PARENT_ID:
+        err = mlx5e_rep_get_port_parent_id(dev, &attr->u.ppid);
+        break;
+    default:
+        return -EOPNOTSUPP;
+    }
+
+    return err;
 }
 
+static const struct switchdev_ops mlx5e_rep_switchdev_ops = {
+    .switchdev_port_attr_get    = mlx5e_attr_get,
+};
+#endif
+
 static void mlx5e_build_rep_netdev(struct net_device *netdev)
 {
 	struct mlx5e_priv *priv = netdev_priv(netdev);
@@ -1496,10 +1891,17 @@ static void mlx5e_build_rep_netdev(struct net_device *netdev)
 		netdev->netdev_ops = &mlx5e_netdev_ops_uplink_rep;
 		/* we want a persistent mac for the uplink rep */
 		mlx5_query_nic_vport_mac_address(mdev, 0, netdev->dev_addr);
+#ifdef HAVE_ETHTOOL_OPS_EXT
+		SET_ETHTOOL_OPS(netdev, &mlx5e_uplink_rep_ethtool_ops);
+		set_ethtool_ops_ext(netdev, &mlx5e_uplink_rep_ethtool_ops_ext);
+#else
 		netdev->ethtool_ops = &mlx5e_uplink_rep_ethtool_ops;
+#endif
+#ifdef HAVE_IEEE_DCBNL_ETS
 #ifdef CONFIG_MLX5_CORE_EN_DCB
 		if (MLX5_CAP_GEN(mdev, qos))
 			netdev->dcbnl_ops = &mlx5e_dcbnl_ops;
+#endif
 #endif
 	} else {
 		netdev->netdev_ops = &mlx5e_netdev_ops_rep;
@@ -1507,11 +1909,22 @@ static void mlx5e_build_rep_netdev(struct net_device *netdev)
 		netdev->ethtool_ops = &mlx5e_rep_ethtool_ops;
 	}
 
+#ifdef HAVE_SWITCHDEV_OPS
+        netdev->switchdev_ops = &mlx5e_rep_switchdev_ops;
+#endif
+
 	netdev->watchdog_timeo    = 15 * HZ;
 
-	netdev->features       |= NETIF_F_NETNS_LOCAL;
+#ifdef HAVE_TC_FLOWER_OFFLOAD
+	netdev->features	 |= NETIF_F_HW_TC | NETIF_F_NETNS_LOCAL;
+#else
+	netdev->features	 |= NETIF_F_NETNS_LOCAL;
+#endif
 
-	netdev->hw_features    |= NETIF_F_HW_TC;
+#ifdef HAVE_NETDEV_HW_FEATURES
+#ifdef HAVE_TC_FLOWER_OFFLOAD
+	netdev->hw_features      |= NETIF_F_HW_TC;
+#endif
 	netdev->hw_features    |= NETIF_F_SG;
 	netdev->hw_features    |= NETIF_F_IP_CSUM;
 	netdev->hw_features    |= NETIF_F_IPV6_CSUM;
@@ -1520,12 +1933,14 @@ static void mlx5e_build_rep_netdev(struct net_device *netdev)
 	netdev->hw_features    |= NETIF_F_TSO6;
 	netdev->hw_features    |= NETIF_F_RXCSUM;
 
+	netdev->features |= netdev->hw_features;
+#endif
+
 	if (rep->vport == MLX5_VPORT_UPLINK)
 		netdev->hw_features |= NETIF_F_HW_VLAN_CTAG_RX;
 	else
 		netdev->features |= NETIF_F_VLAN_CHALLENGED;
 
-	netdev->features |= netdev->hw_features;
 }
 
 static int mlx5e_init_rep(struct mlx5_core_dev *mdev,
@@ -1856,11 +2271,19 @@ static void mlx5e_uplink_rep_enable(struct mlx5e_priv *priv)
 	struct net_device *netdev = priv->netdev;
 	struct mlx5_core_dev *mdev = priv->mdev;
 	struct mlx5e_rep_priv *rpriv = priv->ppriv;
+#if defined(HAVE_NET_DEVICE_MIN_MAX_MTU) || defined(HAVE_NET_DEVICE_MIN_MAX_MTU_EXTENDED)
 	u16 max_mtu;
+#endif
 
+#if defined(HAVE_NET_DEVICE_MIN_MAX_MTU)
 	netdev->min_mtu = ETH_MIN_MTU;
 	mlx5_query_port_max_mtu(priv->mdev, &max_mtu, 1);
 	netdev->max_mtu = MLX5E_HW2SW_MTU(&priv->channels.params, max_mtu);
+#elif defined(HAVE_NET_DEVICE_MIN_MAX_MTU_EXTENDED)
+	netdev->extended->min_mtu = ETH_MIN_MTU;
+	mlx5_query_port_max_mtu(mdev, &max_mtu, 1);
+	netdev->extended->max_mtu = MLX5E_HW2SW_MTU(&priv->channels.params, max_mtu);
+#endif
 	mlx5e_set_dev_port_mtu(priv);
 
 	INIT_WORK(&rpriv->uplink_priv.reoffload_flows_work,
@@ -1869,10 +2292,12 @@ static void mlx5e_uplink_rep_enable(struct mlx5e_priv *priv)
 	mlx5_lag_add(mdev, netdev, false);
 	priv->events_nb.notifier_call = uplink_rep_async_event;
 	mlx5_notifier_register(mdev, &priv->events_nb);
+#ifdef HAVE_IEEE_DCBNL_ETS
 #ifdef CONFIG_MLX5_CORE_EN_DCB
 	mlx5e_dcbnl_initialize(priv);
 	mlx5e_dcbnl_init_app(priv);
 #endif
+#endif
 }
 
 static void mlx5e_uplink_rep_disable(struct mlx5e_priv *priv)
@@ -1880,8 +2305,10 @@ static void mlx5e_uplink_rep_disable(struct mlx5e_priv *priv)
 	struct mlx5_core_dev *mdev = priv->mdev;
 	struct mlx5e_rep_priv *rpriv = priv->ppriv;
 
+#ifdef HAVE_IEEE_DCBNL_ETS
 #ifdef CONFIG_MLX5_CORE_EN_DCB
 	mlx5e_dcbnl_delete_app(priv);
+#endif
 #endif
 	mlx5_notifier_unregister(mdev, &priv->events_nb);
 	cancel_work_sync(&rpriv->uplink_priv.reoffload_flows_work);
@@ -1919,9 +2346,81 @@ static const struct mlx5e_profile mlx5e_uplink_rep_profile = {
 };
 
 /* e-Switch vport representors */
+#ifdef HAVE_SWITCHDEV_H_COMPAT
+static inline int dev_isalive(const struct net_device *dev)
+{
+	return dev->reg_state <= NETREG_REGISTERED;
+}
+
+static ssize_t phys_port_name_show(struct device *dev,
+				   struct device_attribute *attr, char *buf)
+{
+	struct net_device *netdev = to_net_dev(dev);
+	ssize_t ret = -EINVAL;
+
+	if (!rtnl_trylock())
+		return restart_syscall();
+
+	if (dev_isalive(netdev)) {
+		char name[IFNAMSIZ];
+
+		ret = mlx5e_rep_get_phys_port_name(netdev, name, sizeof(name));
+		if (!ret)
+			ret = sprintf(buf, "%s\n", name);
+	}
+	rtnl_unlock();
+
+	return ret;
+}
+
+ssize_t phys_switch_id_show(struct device *dev,
+			    struct device_attribute *attr, char *buf)
+{
+	struct net_device *netdev = to_net_dev(dev);
+	ssize_t ret = -EINVAL;
+
+	if (!rtnl_trylock())
+		return restart_syscall();
+
+	if (dev_isalive(netdev)) {
+		struct switchdev_attr attr = {
+			.orig_dev = netdev,
+			.id = SWITCHDEV_ATTR_ID_PORT_PARENT_ID,
+			.flags = SWITCHDEV_F_NO_RECURSE,
+		};
+#ifdef HAVE_SWITCHDEV_OPS
+		ret = mlx5e_attr_get(netdev, &attr);
+		if (!ret)
+			ret = sprintf(buf, "%*phN\n", attr.u.ppid.id_len,
+				      attr.u.ppid.id);
+#endif
+	}
+	rtnl_unlock();
+
+	return ret;
+}
+
+static DEVICE_ATTR(phys_port_name, S_IRUGO, phys_port_name_show, NULL);
+static DEVICE_ATTR(phys_switch_id, S_IRUGO, phys_switch_id_show, NULL);
+
+static struct attribute *rep_sysfs_attrs[] = {
+	&dev_attr_phys_port_name.attr,
+	&dev_attr_phys_switch_id.attr,
+	NULL,
+};
+
+static struct attribute_group rep_sysfs_attr_group = {
+	.attrs = rep_sysfs_attrs,
+};
+#endif /* HAVE_SWITCHDEV_H_COMPAT */
+
 static int
 mlx5e_vport_rep_load(struct mlx5_core_dev *dev, struct mlx5_eswitch_rep *rep)
 {
+#ifdef HAVE_TC_BLOCK_OFFLOAD
+	struct mlx5e_rep_priv *uplink_rpriv;
+	struct mlx5e_priv *upriv;
+#endif
 	const struct mlx5e_profile *profile;
 	struct mlx5e_rep_priv *rpriv;
 	struct net_device *netdev;
@@ -1955,6 +2454,8 @@ mlx5e_vport_rep_load(struct mlx5_core_dev *dev, struct mlx5_eswitch_rep *rep)
 			goto err_destroy_netdev;
 
 #ifdef HAVE_MINIFLOW
+		uplink_rpriv = mlx5_eswitch_get_uplink_priv(dev->priv.eswitch, REP_ETH);
+		upriv = netdev_priv(uplink_rpriv->netdev);
 		err = tc_setup_cb_egdev_all_register(rpriv->netdev,
 				mlx5e_rep_setup_tc_cb_egdev,
 				upriv);
@@ -1977,11 +2478,31 @@ mlx5e_vport_rep_load(struct mlx5_core_dev *dev, struct mlx5_eswitch_rep *rep)
 		goto err_detach_netdev;
 	}
 
+#ifdef HAVE_TC_SETUP_CB_EGDEV_REGISTER
+	uplink_rpriv = mlx5_eswitch_get_uplink_priv(dev->priv.eswitch, REP_ETH);
+#ifdef HAVE_TC_BLOCK_OFFLOAD
+	upriv = netdev_priv(uplink_rpriv->netdev);
+	err = tc_setup_cb_egdev_register(netdev, mlx5e_rep_setup_tc_cb_egdev,
+					 upriv);
+#else
+	err = tc_setup_cb_egdev_register(netdev, mlx5e_rep_setup_tc_cb,
+					 uplink_rpriv->netdev);
+#endif
+	if (err)
+		goto err_neigh_cleanup;
+#endif
+
+#ifdef HAVE_SWITCHDEV_H_COMPAT
+	if (!netdev->sysfs_groups[0]) {
+		netdev->sysfs_groups[0] = &rep_sysfs_attr_group;
+	}
+#endif
+
 	err = register_netdev(netdev);
 	if (err) {
 		pr_warn("Failed to register representor netdev for vport %d\n",
 			rep->vport);
-		goto err_neigh_cleanup;
+		goto err_egdev_cleanup;
 	}
 
 	if (rep->vport == MLX5_VPORT_UPLINK) {
@@ -1991,7 +2512,18 @@ mlx5e_vport_rep_load(struct mlx5_core_dev *dev, struct mlx5_eswitch_rep *rep)
 
 	return 0;
 
+err_egdev_cleanup:
+#ifdef HAVE_TC_SETUP_CB_EGDEV_REGISTER
+#ifdef HAVE_TC_BLOCK_OFFLOAD
+	tc_setup_cb_egdev_unregister(netdev, mlx5e_rep_setup_tc_cb_egdev,
+				     upriv);
+#else
+	tc_setup_cb_egdev_unregister(netdev, mlx5e_rep_setup_tc_cb,
+				     uplink_rpriv->netdev);
+#endif
+
 err_neigh_cleanup:
+#endif
 	mlx5e_rep_neigh_cleanup(rpriv);
 
 err_detach_netdev:
@@ -1999,10 +2531,14 @@ err_detach_netdev:
 
 err_unregister_egdev_all:
 #ifdef HAVE_MINIFLOW
-	if (rep->vport == MLX5_VPORT_UPLINK)
+	if (rep->vport == MLX5_VPORT_UPLINK) {
+		uplink_rpriv = mlx5_eswitch_get_uplink_priv(dev->priv.eswitch,
+							    REP_ETH);
+		upriv = netdev_priv(uplink_rpriv->netdev);
 		tc_setup_cb_egdev_all_unregister(rpriv->netdev,
-				mlx5e_rep_setup_tc_cb_egdev,
-				upriv);
+						 mlx5e_rep_setup_tc_cb_egdev,
+						 upriv);
+	}
 
 err_destroy_mdev_resources:
 #endif
@@ -2018,6 +2554,10 @@ err_destroy_netdev:
 static void
 mlx5e_vport_rep_unload(struct mlx5_eswitch_rep *rep)
 {
+#ifdef HAVE_TC_BLOCK_OFFLOAD
+	struct mlx5e_rep_priv *uplink_rpriv;
+	struct mlx5e_priv *upriv;
+#endif
 	struct mlx5e_rep_priv *rpriv = mlx5e_rep_to_rep_priv(rep);
 	struct net_device *netdev = rpriv->netdev;
 	struct mlx5e_priv *priv = netdev_priv(netdev);
@@ -2029,10 +2569,22 @@ mlx5e_vport_rep_unload(struct mlx5_eswitch_rep *rep)
 	}
 
 	unregister_netdev(netdev);
+#ifdef HAVE_TC_SETUP_CB_EGDEV_REGISTER
+	uplink_rpriv = mlx5_eswitch_get_uplink_priv(priv->mdev->priv.eswitch,
+						    REP_ETH);
+#ifdef HAVE_TC_BLOCK_OFFLOAD
+	upriv = netdev_priv(uplink_rpriv->netdev);
+	tc_setup_cb_egdev_unregister(netdev, mlx5e_rep_setup_tc_cb_egdev,
+				     upriv);
+#endif
+#endif
 	mlx5e_rep_neigh_cleanup(rpriv);
 	mlx5e_detach_netdev(priv);
 	if (rep->vport == MLX5_VPORT_UPLINK) {
 #ifdef HAVE_MINIFLOW
+		uplink_rpriv = mlx5_eswitch_get_uplink_priv(priv->mdev->priv.eswitch,
+				REP_ETH);
+		upriv = netdev_priv(uplink_rpriv->netdev);
 		tc_setup_cb_egdev_all_unregister(rpriv->netdev,
 				mlx5e_rep_setup_tc_cb_egdev,
 				upriv);
